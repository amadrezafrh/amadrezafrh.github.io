<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Understanding Diffusion Models for Audio Generation - Amadreza Farahani</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/styles.css" />
</head>
<body>
  <nav class="nav">
    <div class="nav-content">
      <a href="../index.html" class="nav-logo">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
          <rect x="3" y="3" width="18" height="18" rx="2"/>
          <path d="M9 9h6M9 12h6M9 15h4"/>
        </svg>
      </a>
      <ul class="nav-links">
        <li><a href="../index.html#about">About</a></li>
        <li><a href="../index.html#experience">Experience</a></li>
        <li><a href="../index.html#education">Education</a></li>
        <li><a href="../projects.html">Projects</a></li>
        <li><a href="../blog.html">Blog</a></li>
        <li><a href="../index.html#contact">Contact</a></li>
      </ul>
    </div>
  </nav>

  <main class="page-content blog-page">
    <a href="../blog.html" class="back-link">Back to Blog</a>
    
    <article class="blog-detail">
      <h1>Understanding Diffusion Models for Audio Generation</h1>
      <p class="blog-meta">November 2025</p>
      <p class="blog-keywords">
        <span>Diffusion Models</span>
        <span>Audio</span>
        <span>Deep Learning</span>
      </p>

      <section class="blog-content">
        <p>
          Diffusion models have revolutionized image generation, but their application to audio 
          presents unique challenges and opportunities. In this post, I explore the key concepts 
          behind applying diffusion processes to audio synthesis.
        </p>

        <h2>The Challenge of Audio</h2>
        <p>
          Unlike images, audio signals are inherently sequential and require capturing long-range 
          temporal dependencies. Traditional diffusion approaches need adaptation to handle the 
          unique characteristics of audio data.
        </p>

        <h2>Diffusion Transformers</h2>
        <p>
          By combining the denoising process of diffusion models with the attention mechanisms 
          of transformers, we can build models that effectively capture both local acoustic 
          features and global temporal structure.
        </p>

        <h2>Applications in Voice Conversion</h2>
        <p>
          My thesis work explored using these techniques for zero-shot voice conversion, where 
          the goal is to transform speech from one speaker to sound like another without 
          paired training data.
        </p>
      </section>
    </article>
  </main>

  <footer class="footer">
    <p>&copy; <span id="year"></span> Amadreza Farahani</p>
  </footer>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>
</html>
